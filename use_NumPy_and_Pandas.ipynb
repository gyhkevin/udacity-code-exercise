{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_employment(countries, employment):\n",
    "    max_country = None\n",
    "    max_employment = 0\n",
    "    \n",
    "    for i in xrange(len(countries)):\n",
    "        country = countries[i]\n",
    "        country_employment = employment[i]\n",
    "        \n",
    "        if country_employment > max_employment:\n",
    "            max_country = country\n",
    "            max_employment = country_employment\n",
    "    return (max_country, max_employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_employment(countries, employment):\n",
    "    i = employment.argmax()\n",
    "    return (countries[i], employment[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First 20 countries with employment data\n",
    "countries = np.array([\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina',\n",
    "    'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
    "    'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium',\n",
    "    'Belize', 'Benin', 'Bhutan', 'Bolivia',\n",
    "    'Bosnia and Herzegovina'\n",
    "])\n",
    "\n",
    "# Employment data in 2007 for those 20 countries\n",
    "employment = np.array([\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print countries[0]\n",
    "    print countries[3]\n",
    "\n",
    "# Slicing\n",
    "if False:\n",
    "    print countries[0:3]\n",
    "    print countries[:3]\n",
    "    print countries[17:]\n",
    "    print countries[:]\n",
    "\n",
    "# Element types\n",
    "if False:\n",
    "    print countries.dtype\n",
    "    print employment.dtype\n",
    "    print np.array([0, 1, 2, 3]).dtype\n",
    "    print np.array([1.0, 1.5, 2.0, 2.5]).dtype\n",
    "    print np.array([True, False, True]).dtype\n",
    "    print np.array(['AL', 'AK', 'AZ', 'AR', 'CA']).dtype\n",
    "\n",
    "# Looping\n",
    "if False:\n",
    "    for country in countries:\n",
    "        print 'Examining country {}'.format(country)\n",
    "\n",
    "    for i in range(len(countries)):\n",
    "        country = countries[i]\n",
    "        country_employment = employment[i]\n",
    "        print 'Country {} has employment {}'.format(country,\n",
    "                country_employment)\n",
    "\n",
    "# Numpy functions\n",
    "if True:\n",
    "    print employment.mean()\n",
    "    print employment.std()\n",
    "    print employment.max()\n",
    "    print employment.sum()\n",
    "\n",
    "def max_employment(countries, employment):\n",
    "    '''\n",
    "    Fill in this function to return the name of the country\n",
    "    with the highest employment in the given employment\n",
    "    data, and the employment in that country.\n",
    "    '''\n",
    "    max_country = countries[3]      # Replace this with your code\n",
    "    max_value = employment.max()   # Replace this with your code\n",
    "\n",
    "    return (max_country, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Arithmetic operations between 2 NumPy arrays\n",
    "if False:\n",
    "    a = np.array([1, 2, 3, 4])\n",
    "    b = np.array([1, 2, 1, 2])\n",
    "    \n",
    "    print a + b\n",
    "    print a - b\n",
    "    print a * b\n",
    "    print a / b\n",
    "    print a ** b\n",
    "    \n",
    "# Arithmetic operations between a NumPy array and a single number\n",
    "if False:\n",
    "    a = np.array([1, 2, 3, 4])\n",
    "    b = 2\n",
    "    \n",
    "    print a + b\n",
    "    print a - b\n",
    "    print a * b\n",
    "    print a / b\n",
    "    print a ** b\n",
    "    \n",
    "# Logical operations with NumPy arrays\n",
    "if True:\n",
    "    a = np.array([True, True, False, False])\n",
    "    b = np.array([True, False, True, False])\n",
    "    \n",
    "    print a & b\n",
    "    print a | b\n",
    "    print ~a\n",
    "    \n",
    "    print a & True\n",
    "    print a & False\n",
    "    \n",
    "    print a | True\n",
    "    print a | False\n",
    "    \n",
    "# Comparison operations between 2 NumPy Arrays\n",
    "if False:\n",
    "    a = np.array([1, 2, 3, 4, 5])\n",
    "    b = np.array([5, 4, 3, 2, 1])\n",
    "    \n",
    "    print a > b\n",
    "    print a >= b\n",
    "    print a < b\n",
    "    print a <= b\n",
    "    print a == b\n",
    "    print a != b\n",
    "    \n",
    "# Comparison operations between a NumPy array and a single number\n",
    "if False:\n",
    "    a = np.array([1, 2, 3, 4])\n",
    "    b = 2\n",
    "    \n",
    "    print a > b\n",
    "    print a >= b\n",
    "    print a < b\n",
    "    print a <= b\n",
    "    print a == b\n",
    "    print a != b\n",
    "    \n",
    "# First 20 countries with school completion data\n",
    "countries = np.array([\n",
    "       'Algeria', 'Argentina', 'Armenia', 'Aruba', 'Austria','Azerbaijan',\n",
    "       'Bahamas', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Bolivia',\n",
    "       'Botswana', 'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi',\n",
    "       'Cambodia', 'Cameroon', 'Cape Verde'\n",
    "])\n",
    "\n",
    "# Female school completion rate in 2007 for those 20 countries\n",
    "female_completion = np.array([\n",
    "    97.35583,  104.62379,  103.02998,   95.14321,  103.69019,\n",
    "    98.49185,  100.88828,   95.43974,   92.11484,   91.54804,\n",
    "    95.98029,   98.22902,   96.12179,  119.28105,   97.84627,\n",
    "    29.07386,   38.41644,   90.70509,   51.7478 ,   95.45072\n",
    "])\n",
    "\n",
    "# Male school completion rate in 2007 for those 20 countries\n",
    "male_completion = np.array([\n",
    "     95.47622,  100.66476,   99.7926 ,   91.48936,  103.22096,\n",
    "     97.80458,  103.81398,   88.11736,   93.55611,   87.76347,\n",
    "    102.45714,   98.73953,   92.22388,  115.3892 ,   98.70502,\n",
    "     37.00692,   45.39401,   91.22084,   62.42028,   90.66958\n",
    "])\n",
    "\n",
    "def overall_completion_rate(female_completion, male_completion):\n",
    "    '''\n",
    "    Fill in this function to return a NumPy array containing the overall\n",
    "    school completion rate for each country. The arguments are NumPy\n",
    "    arrays giving the female and male completion of each country in\n",
    "    the same order.\n",
    "    '''\n",
    "    return male_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First 20 countries with employment data\n",
    "countries = np.array([\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina',\n",
    "    'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
    "    'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium',\n",
    "    'Belize', 'Benin', 'Bhutan', 'Bolivia',\n",
    "    'Bosnia and Herzegovina'\n",
    "])\n",
    "\n",
    "# Employment data in 2007 for those 20 countries\n",
    "employment = np.array([\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076\n",
    "])\n",
    "\n",
    "# Change this country name to change what country will be printed when you\n",
    "# click \"Test Run\". Your function will be called to determine the standardized\n",
    "# score for this country for each of the given 5 Gapminder variables in 2007.\n",
    "# The possible country names are available in the Downloadables section.\n",
    "\n",
    "country_name = 'United States'\n",
    "\n",
    "def standardize_data(values):\n",
    "    '''\n",
    "    Fill in this function to return a standardized version of the given values,\n",
    "    which will be in a NumPy array. Each value should be translated into the\n",
    "    number of standard deviations that value is away from the mean of the data.\n",
    "    (A positive number indicates a value higher than the mean, and a negative\n",
    "    number indicates a value lower than the mean.)\n",
    "    '''\n",
    "    standardize_value = (values - values.mean()) / values.std()\n",
    "    return standardize_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Using index arrays\n",
    "if False:\n",
    "    a = np.array([1, 2, 3, 4])\n",
    "    b = np.array([True, True, False, False])\n",
    "    \n",
    "    print a[b]\n",
    "    print a[np.array([True, False, True, False])]\n",
    "    \n",
    "# Creating the index array using vectorized operations\n",
    "if False:\n",
    "    a = np.array([1, 2, 3, 2, 1])\n",
    "    b = (a >= 2)\n",
    "    \n",
    "    print a[b]\n",
    "    print a[a >= 2]\n",
    "    \n",
    "# Creating the index array using vectorized operations on another array\n",
    "if False:\n",
    "    a = np.array([1, 2, 3, 4, 5])\n",
    "    b = np.array([1, 2, 3, 2, 1])\n",
    "    \n",
    "    print b == 2\n",
    "    print a[b == 2]\n",
    "\n",
    "def mean_time_for_paid_students(time_spent, days_to_cancel):\n",
    "    '''\n",
    "    Fill in this function to calculate the mean time spent in the classroom\n",
    "    for students who stayed enrolled at least (greater than or equal to) 7 days.\n",
    "    Unlike in Lesson 1, you can assume that days_to_cancel will contain only\n",
    "    integers (there are no students who have not canceled yet).\n",
    "    \n",
    "    The arguments are NumPy arrays. time_spent contains the amount of time spent\n",
    "    in the classroom for each student, and days_to_cancel contains the number\n",
    "    of days until each student cancel. The data is given in the same order\n",
    "    in both arrays.\n",
    "    '''\n",
    "    return time_spent[days_to_cancel >= 7].mean()\n",
    "\n",
    "# Time spent in the classroom in the first week for 20 students\n",
    "time_spent = np.array([\n",
    "       12.89697233,    0.        ,   64.55043217,    0.        ,\n",
    "       24.2315615 ,   39.991625  ,    0.        ,    0.        ,\n",
    "      147.20683783,    0.        ,    0.        ,    0.        ,\n",
    "       45.18261617,  157.60454283,  133.2434615 ,   52.85000767,\n",
    "        0.        ,   54.9204785 ,   26.78142417,    0.\n",
    "])\n",
    "\n",
    "# Days to cancel for 20 students\n",
    "days_to_cancel = np.array([\n",
    "      4,   5,  37,   3,  12,   4,  35,  38,   5,  37,   3,   3,  68,\n",
    "     38,  98,   2, 249,   2, 127,  35\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = ['Albania', 'Algeria', 'Andorra', 'Angola', 'Antigua and Barbuda',\n",
    "             'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan',\n",
    "             'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus',\n",
    "             'Belgium', 'Belize', 'Benin', 'Bhutan', 'Bolivia']\n",
    "\n",
    "life_expectancy_values = [74.7,  75. ,  83.4,  57.6,  74.6,  75.4,  72.3,  81.5,  80.2,\n",
    "                          70.3,  72.1,  76.4,  68.1,  75.2,  69.8,  79.4,  70.8,  62.7,\n",
    "                          67.3,  70.6]\n",
    "\n",
    "gdp_values = [ 1681.61390973,   2155.48523109,  21495.80508273,    562.98768478,\n",
    "              13495.1274663 ,   9388.68852258,   1424.19056199,  24765.54890176,\n",
    "              27036.48733192,   1945.63754911,  21721.61840978,  13373.21993972,\n",
    "                483.97086804,   9783.98417323,   2253.46411147,  25034.66692293,\n",
    "               3680.91642923,    366.04496652,   1175.92638695,   1132.21387981]\n",
    "\n",
    "# Life expectancy and gdp data in 2007 for 20 countries\n",
    "life_expectancy = pd.Series(life_expectancy_values)\n",
    "gdp = pd.Series(gdp_values)\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements and slicing\n",
    "if False:\n",
    "    print life_expectancy[0]\n",
    "    print gdp[3:6]\n",
    "    \n",
    "# Looping\n",
    "if False:\n",
    "    for country_life_expectancy in life_expectancy:\n",
    "        print 'Examining life expectancy {}'.format(country_life_expectancy)\n",
    "        \n",
    "# Pandas functions\n",
    "if False:\n",
    "    print life_expectancy.mean()\n",
    "    print life_expectancy.std()\n",
    "    print gdp.max()\n",
    "    print gdp.sum()\n",
    "\n",
    "# Vectorized operations and index arrays\n",
    "if False:\n",
    "    a = pd.Series([1, 2, 3, 4])\n",
    "    b = pd.Series([1, 2, 1, 2])\n",
    "  \n",
    "    print a + b\n",
    "    print a * 2\n",
    "    print a >= 3\n",
    "    print a[a >= 3]\n",
    "   \n",
    "def variable_correlation(variable1, variable2):\n",
    "    '''\n",
    "    Fill in this function to calculate the number of data points for which\n",
    "    the directions of variable1 and variable2 relative to the mean are the\n",
    "    same, and the number of data points for which they are different.\n",
    "    Direction here means whether each value is above or below its mean.\n",
    "    \n",
    "    You can classify cases where the value is equal to the mean for one or\n",
    "    both variables however you like.\n",
    "    \n",
    "    Each argument will be a Pandas series.\n",
    "    \n",
    "    For example, if the inputs were pd.Series([1, 2, 3, 4]) and\n",
    "    pd.Series([4, 5, 6, 7]), then the output would be (4, 0).\n",
    "    This is because 1 and 4 are both below their means, 2 and 5 are both\n",
    "    below, 3 and 6 are both above, and 4 and 7 are both above.\n",
    "    \n",
    "    On the other hand, if the inputs were pd.Series([1, 2, 3, 4]) and\n",
    "    pd.Series([7, 6, 5, 4]), then the output would be (0, 4).\n",
    "    This is because 1 is below its mean but 7 is above its mean, and\n",
    "    so on.\n",
    "    '''\n",
    "    both_above = (variable1 > variable1.mean()) & (variable2 > variable2.mean())\n",
    "    both_below = (variable1 < variable1.mean()) & (variable2 < variable2.mean())\n",
    "    is_same_direction = both_above | both_below\n",
    "    num_same_direction = is_same_direction.sum()        # Replace this with your code\n",
    "    num_different_direction = len(variable1) - num_same_direction  # Replace this with your code\n",
    "    \n",
    "    return (num_same_direction, num_different_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_correlation(life_expectancy, gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "countries = [\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola',\n",
    "    'Argentina', 'Armenia', 'Australia', 'Austria',\n",
    "    'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh',\n",
    "    'Barbados', 'Belarus', 'Belgium', 'Belize',\n",
    "    'Benin', 'Bhutan', 'Bolivia', 'Bosnia and Herzegovina',\n",
    "]\n",
    "\n",
    "\n",
    "employment_values = [\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076,\n",
    "]\n",
    "\n",
    "# Employment data in 2007 for 20 countries\n",
    "employment = pd.Series(employment_values, index=countries)\n",
    "\n",
    "def max_employment(employment):\n",
    "    '''\n",
    "    Fill in this function to return the name of the country\n",
    "    with the highest employment in the given employment\n",
    "    data, and the employment in that country.\n",
    "    \n",
    "    The input will be a Pandas series where the values\n",
    "    are employment and the index is country names.\n",
    "    \n",
    "    Try using the Pandas idxmax() function. Documention can\n",
    "    be found here:\n",
    "    http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.idxmax.html\n",
    "    '''\n",
    "    max_country = employment.argmax()      # Replace this with your code\n",
    "    max_value = employment.loc[max_country]   # Replace this with your code\n",
    "\n",
    "    return (max_country, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Angola', 75.699996949999999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_employment(employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c    13.0\n",
      "d    24.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Addition when indexes are the same\n",
    "if False:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "    print s1 + s2\n",
    "\n",
    "# Indexes have same elements in a different order\n",
    "if False:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['b', 'd', 'a', 'c'])\n",
    "    print s1 + s2\n",
    "\n",
    "# Indexes overlap, but do not have exactly the same elements\n",
    "if True:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['c', 'd', 'e', 'f'])\n",
    "    sum_result = s1 + s2\n",
    "    print sum_result.dropna()\n",
    "\n",
    "# Indexes do not overlap\n",
    "if False:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['e', 'f', 'g', 'h'])\n",
    "    sum_result = s1 + s2\n",
    "    print sum_result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change False to True to see what the following block of code does\n",
    "\n",
    "# Example pandas apply() usage (although this could have been done\n",
    "# without apply() using vectorized operations)\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4, 5])\n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "    print s.apply(add_one)\n",
    "\n",
    "names = pd.Series([\n",
    "    'Andre Agassi',\n",
    "    'Barry Bonds',\n",
    "    'Christopher Columbus',\n",
    "    'Daniel Defoe',\n",
    "    'Emilio Estevez',\n",
    "    'Fred Flintstone',\n",
    "    'Greta Garbo',\n",
    "    'Humbert Humbert',\n",
    "    'Ivan Ilych',\n",
    "    'James Joyce',\n",
    "    'Keira Knightley',\n",
    "    'Lois Lane',\n",
    "    'Mike Myers',\n",
    "    'Nick Nolte',\n",
    "    'Ozzy Osbourne',\n",
    "    'Pablo Picasso',\n",
    "    'Quirinus Quirrell',\n",
    "    'Rachael Ray',\n",
    "    'Susan Sarandon',\n",
    "    'Tina Turner',\n",
    "    'Ugueth Urbina',\n",
    "    'Vince Vaughn',\n",
    "    'Woodrow Wilson',\n",
    "    'Yoji Yamada',\n",
    "    'Zinedine Zidane'\n",
    "])\n",
    "def reverse_name(name):\n",
    "    split_name = name.split(' ')\n",
    "    first_name = split_name[0]\n",
    "    last_name = split_name[1]\n",
    "    return last_name + ', ' + first_name\n",
    "\n",
    "def reverse_names(names):\n",
    "    '''\n",
    "    Fill in this function to return a new series where each name\n",
    "    in the input series has been transformed from the format\n",
    "    \"Firstname Lastname\" to \"Lastname, FirstName\".\n",
    "    \n",
    "    Try to use the Pandas apply() function rather than a loop.\n",
    "    '''\n",
    "    return names.apply(reverse_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# The following code reads all the Gapminder data into Pandas DataFrames. You'll\n",
    "# learn about DataFrames next lesson.\n",
    "\n",
    "path = '/Users/kevin/Source/udacity/data/NumPy_and_Pandas1/'\n",
    "employment = pd.read_csv(path + 'employment-above-15.csv', index_col='Country')\n",
    "female_completion = pd.read_csv(path + 'female-completion-rate.csv', index_col='Country')\n",
    "male_completion = pd.read_csv(path + 'male-completion-rate.csv', index_col='Country')\n",
    "life_expectancy = pd.read_csv(path + 'life-expectancy.csv', index_col='Country')\n",
    "gdp = pd.read_csv(path + 'gdp-per-capita.csv', index_col='Country')\n",
    "\n",
    "# The following code creates a Pandas Series for each variable for the United States.\n",
    "# You can change the string 'United States' to a country of your choice.\n",
    "\n",
    "employment_us = employment.loc['United States']\n",
    "female_completion_us = female_completion.loc['United States']\n",
    "male_completion_us = male_completion.loc['United States']\n",
    "life_expectancy_us = life_expectancy.loc['United States']\n",
    "gdp_us = gdp.loc['United States']\n",
    "\n",
    "# Uncomment the following line of code to see the available country names\n",
    "# print employment.index.values\n",
    "\n",
    "# Use the Series defined above to create a plot of each variable over time for\n",
    "# the country of your choice. You will only be able to display one plot at a time\n",
    "# with each \"Test Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2342.5999999999999, 3239.9000000000001)\n"
     ]
    }
   ],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print ridership[1, 3]\n",
    "    print ridership[1:3, 3:5]\n",
    "    print ridership[1, :]\n",
    "    \n",
    "# Vectorized operations on rows or columns\n",
    "if False:\n",
    "    print ridership[0, :] + ridership[1, :]\n",
    "    print ridership[:, 0] + ridership[:, 1]\n",
    "    \n",
    "# Vectorized operations on entire arrays\n",
    "if False:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print a + b\n",
    "\n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    max_station = ridership[0, :].argmax()\n",
    "    overall_mean = ridership.mean() # Replace this with your code\n",
    "    mean_for_max = ridership[:, max_station].mean() # Replace this with your code\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "print mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3239.9000000000001, 1071.2)\n"
     ]
    }
   ],
   "source": [
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    station_rider = ridership.mean(axis=0)\n",
    "    max_daily_ridership = station_rider.max()     # Replace this with your code\n",
    "    min_daily_ridership = station_rider.min()     # Replace this with your code\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)\n",
    "print min_and_max_riders_per_day(ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2342.5999999999999, 3239.9)\n"
     ]
    }
   ],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# DataFrame creation\n",
    "if False:\n",
    "    # You can create a DataFrame out of a dictionary mapping column names to values\n",
    "    df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df_1\n",
    "\n",
    "    # You can also use a list of lists or a 2D NumPy array\n",
    "    df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "    print df_2\n",
    "   \n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print ridership_df.iloc[0]\n",
    "    print ridership_df.loc['05-05-11']\n",
    "    print ridership_df['R003']\n",
    "    print ridership_df.iloc[1, 3]\n",
    "    \n",
    "# Accessing multiple rows\n",
    "if False:\n",
    "    print ridership_df.iloc[1:4]\n",
    "    \n",
    "# Accessing multiple columns\n",
    "if False:\n",
    "    print ridership_df[['R003', 'R005']]\n",
    "    \n",
    "# Pandas axis\n",
    "if False:\n",
    "    df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df.sum()\n",
    "    print df.sum(axis=1)\n",
    "    print df.values.sum()\n",
    "    \n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    max_station = ridership.iloc[0].argmax()\n",
    "    overall_mean = ridership.values.mean() # Replace this with your code\n",
    "    mean_for_max = ridership[max_station].mean() # Replace this with your code\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "print mean_riders_for_max_station(ridership_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examples of vectorized operations on DataFrames:\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "    \n",
    "# Adding DataFrames with overlapping column names \n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print df1 + df2\n",
    "\n",
    "# --- Quiz ---\n",
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    return entries_and_exits - entries_and_exits.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>214.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn  EXITSn\n",
       "0       NaN     NaN\n",
       "1      23.0     8.0\n",
       "2      18.0    18.0\n",
       "3      71.0    54.0\n",
       "4     170.0    44.0\n",
       "5     214.0    42.0\n",
       "6      87.0    11.0\n",
       "7      10.0     3.0\n",
       "8      36.0    89.0\n",
       "9     153.0   333.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        exam1 exam2\n",
       "Andre       F     F\n",
       "Barry       B     D\n",
       "Chris       C     F\n",
       "Dan         C     F\n",
       "Emilio      B     D\n",
       "Fred        C     F\n",
       "Greta       A     C\n",
       "Humbert     D     F\n",
       "Ivan        A     C\n",
       "James       B     D"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame applymap()\n",
    "if False:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print df.applymap(add_one)\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def convert_grade(grade):\n",
    "    if grade >= 90:\n",
    "        score = 'A'\n",
    "    elif grade >= 80:\n",
    "        score = 'B'\n",
    "    elif grade >= 70:\n",
    "        score = 'C'\n",
    "    elif grade >= 60:\n",
    "        score = 'D'\n",
    "    else:\n",
    "        score = 'F'\n",
    "    return score\n",
    "    \n",
    "def convert_grades(grades):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    return grades.applymap(convert_grade)\n",
    "convert_grades(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply()\n",
    "if False:\n",
    "    def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                       labels=['F', 'D', 'C', 'B', 'A'])\n",
    "        \n",
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print convert_grades_curve(grades_df['exam1'])\n",
    "    \n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    print grades_df.apply(convert_grades_curve)\n",
    "    \n",
    "def standardize_column(column):\n",
    "    return (column - column.mean()) / column.std(ddof=0)\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    return df.apply(standardize_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Andre     -2.196525\n",
       "Barry      0.208891\n",
       "Chris      0.018990\n",
       "Dan       -0.170911\n",
       "Emilio     0.715295\n",
       "Fred      -0.487413\n",
       "Greta      0.841896\n",
       "Humbert   -0.803916\n",
       "Ivan       1.284999\n",
       "James      0.588694\n",
       "Name: exam1, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_column(grades_df['exam1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>-2.196525</td>\n",
       "      <td>-2.186335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>0.208891</td>\n",
       "      <td>0.366571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>0.018990</td>\n",
       "      <td>-0.091643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>-0.170911</td>\n",
       "      <td>-0.091643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>0.715295</td>\n",
       "      <td>0.628408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>-0.487413</td>\n",
       "      <td>-0.418938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>0.841896</td>\n",
       "      <td>1.413917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>-0.803916</td>\n",
       "      <td>-0.746234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>1.284999</td>\n",
       "      <td>0.955703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0.588694</td>\n",
       "      <td>0.170194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            exam1     exam2\n",
       "Andre   -2.196525 -2.186335\n",
       "Barry    0.208891  0.366571\n",
       "Chris    0.018990 -0.091643\n",
       "Dan     -0.170911 -0.091643\n",
       "Emilio   0.715295  0.628408\n",
       "Fred    -0.487413 -0.418938\n",
       "Greta    0.841896  1.413917\n",
       "Humbert -0.803916 -0.746234\n",
       "Ivan     1.284999  0.955703\n",
       "James    0.588694  0.170194"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "if False:   \n",
    "    print df.apply(np.mean)\n",
    "    print df.apply(np.max)\n",
    "    \n",
    "def second_largest_in_column(column):\n",
    "    sort_column = column.sort_values(ascending=False)\n",
    "    return sort_column.iloc[1]\n",
    "    \n",
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "    return df.apply(second_largest_in_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     4\n",
       "b    40\n",
       "c    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_largest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding a Series to a one-row DataFrame \n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding when DataFrame column names don't match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding using +\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding with axis='index'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='index')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "# Adding with axis='columns'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='columns')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    return df.apply(standardize_rows)\n",
    "\n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    mean_diff = df.sub(df.mean(axis='columns'), axis='index')\n",
    "    column_std = mean_diff.div(df.std(axis='columns', ddof=0), axis='index')\n",
    "    return mean_diff / column_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(\"No axis named columns for object type <class 'pandas.core.series.Series'>\", u'occurred at index exam1')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4109f632cec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrades_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-fee111cff07f>\u001b[0m in \u001b[0;36mstandardize\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mYou\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myou\u001b[0m \u001b[0mdid\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     '''\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstandardize_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstandardize_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4260\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4261\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4262\u001b[0;31m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[1;32m   4263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4357\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4358\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4359\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-fee111cff07f>\u001b[0m in \u001b[0;36mstandardize_rows\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mchallenging\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mstandardizing\u001b[0m \u001b[0meach\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     '''\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmean_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mcolumn_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean_diff\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcolumn_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6340\u001b[0m                                       skipna=skipna)\n\u001b[1;32m   6341\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0;32m-> 6342\u001b[0;31m                             numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m   6343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6344\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m             \u001b[0;31m# Validate that 'axis' is consistent with Series's single axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                 raise NotImplementedError('Series.{0} does not implement '\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         raise ValueError('No axis named {0} for object type {1}'\n\u001b[0;32m--> 353\u001b[0;31m                          .format(axis, type(self)))\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: (\"No axis named columns for object type <class 'pandas.core.series.Series'>\", u'occurred at index exam1')"
     ]
    }
   ],
   "source": [
    "standardize(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print example_df\n",
    "    \n",
    "# Examine groups\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data.sum()\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print grouped_data.sum()['value']\n",
    "    \n",
    "    print '\\n' # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print grouped_data['value'].sum()\n",
    "    \n",
    "filename = '/datasets/ud170/subway/nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print example_df\n",
    "    \n",
    "# Examine groups\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data.sum()\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print grouped_data.sum()['value']\n",
    "    \n",
    "    print '\\n' # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print grouped_data['value'].sum()\n",
    "    \n",
    "filename = '/datasets/ud170/subway/nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot.\n",
    "ridership_by_day = subway_df.groupby('dayweek').mean()['ENTRIESn_hourly']\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "ridership_by_day.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Standardize each group\n",
    "if False:\n",
    "    def standardize(xs):\n",
    "        return (xs - xs.mean()) / xs.std()\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(standardize)\n",
    "    \n",
    "# Find second largest value in each group\n",
    "if False:\n",
    "    def second_largest(xs):\n",
    "        sorted_xs = xs.sort(inplace=False, ascending=False)\n",
    "        return sorted_xs.iloc[1]\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(second_largest)\n",
    "\n",
    "# --- Quiz ---\n",
    "# DataFrame with cumulative entries and exits for multiple stations\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    \n",
    "    Hint: Take a look at the `get_hourly_entries_and_exits()` function\n",
    "    you wrote in a previous quiz, DataFrame Vectorized Operations. If\n",
    "    you copy it here and rename it, you can use it and the `.apply()`\n",
    "    function to help solve this problem.\n",
    "    '''\n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132.0</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn  EXITSn\n",
       "0       NaN     NaN\n",
       "1       NaN     NaN\n",
       "2      23.0     8.0\n",
       "3      14.0     8.0\n",
       "4      18.0    18.0\n",
       "5      29.0   205.0\n",
       "6      71.0    54.0\n",
       "7     132.0   593.0\n",
       "8     170.0    44.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridership_df.groupby('UNIT')[['ENTRIESn', 'EXITSn']].apply(get_hourly_entries_and_exits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    return subway_df.merge(weather_df, on=['DATEn','hour','latitude','longitude'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>hour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>fog</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>4388348</td>\n",
       "      <td>2911036</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>4389885</td>\n",
       "      <td>2912127</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>4391507</td>\n",
       "      <td>2913223</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>4393043</td>\n",
       "      <td>2914284</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>14656120</td>\n",
       "      <td>14451774</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>14656174</td>\n",
       "      <td>14451851</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>14660126</td>\n",
       "      <td>14454734</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>14664247</td>\n",
       "      <td>14457780</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>14668301</td>\n",
       "      <td>14460818</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATEn  ENTRIESn    EXITSn  UNIT  hour   latitude  longitude  fog  \\\n",
       "0  05-01-11   4388333   2911002  R003     0  40.689945 -73.872564    0   \n",
       "1  05-02-11   4388348   2911036  R003     0  40.689945 -73.872564    0   \n",
       "2  05-03-11   4389885   2912127  R003     0  40.689945 -73.872564    0   \n",
       "3  05-04-11   4391507   2913223  R003     0  40.689945 -73.872564    0   \n",
       "4  05-05-11   4393043   2914284  R003     0  40.689945 -73.872564    0   \n",
       "5  05-01-11  14656120  14451774  R004     0  40.691320 -73.867135    0   \n",
       "6  05-02-11  14656174  14451851  R004     0  40.691320 -73.867135    0   \n",
       "7  05-03-11  14660126  14454734  R004     0  40.691320 -73.867135    0   \n",
       "8  05-04-11  14664247  14457780  R004     0  40.691320 -73.867135    0   \n",
       "9  05-05-11  14668301  14460818  R004     0  40.691320 -73.867135    0   \n",
       "\n",
       "   pressurei  rain  tempi  wspdi  \n",
       "0      30.24     0   52.0    8.1  \n",
       "1      30.32     0   48.9    6.9  \n",
       "2      30.14     0   54.0    3.5  \n",
       "3      29.98     0   57.2   15.0  \n",
       "4      30.01     0   48.9   15.0  \n",
       "5      30.24     0   52.0    8.1  \n",
       "6      30.32     0   48.9    6.9  \n",
       "7      30.14     0   54.0    3.5  \n",
       "8      29.98     0   57.2   15.0  \n",
       "9      30.01     0   48.9   15.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_dfs(subway_df, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
